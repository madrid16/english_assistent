import openai
from config import OPENAI_API_KEY

class DialogManager:
    def __init__(self, model="gpt-4o-mini", language="en"):
        """
        model: Modelo de OpenAI a utilizar (gpt-4o, gpt-4o-mini, gpt-5, etc.)
        language: Idioma principal de la conversaciÃ³n
        """
        openai.api_key = OPENAI_API_KEY
        self.model = model
        self.language = language
        self.context = []

    def generate_response(self, user_input):
        """
        Genera una respuesta en funciÃ³n del input del usuario manteniendo el contexto.
        Devuelve: respuesta del asistente, frase objetivo, y si la respuesta es larga.
        """
        print("ğŸ¤– Generando respuesta...")

        keywords_expansion = ["explica", "explÃ­came", "detallado", "dame un ejemplo", "mÃ¡s detalle", "mÃ¡s largo"]
        breve = not any(kw in user_input.lower() for kw in keywords_expansion)

        # Sistema prompt para GPT
        system_prompt = (
            "Eres un asistente de inglÃ©s. Da respuestas claras y breves (mÃ¡x. 40 palabras). "
            "Usa vocabulario adecuado al nivel A2-B1. "
            "Genera una frase objetivo en inglÃ©s solo si la frase del usuario es educativa, prÃ¡ctica o un ejemplo Ãºtil. "
            "No generes frase objetivo para saludos, despedidas o frases muy cortas. "
            "Responde siempre en JSON con 'reply' y opcional 'frase_objetivo'."
        ) if breve else (
            "Eres un asistente de inglÃ©s que da explicaciones completas con ejemplos. "
            "Genera una frase objetivo en inglÃ©s solo si la frase del usuario es educativa, prÃ¡ctica o un ejemplo Ãºtil. "
            "No generes frase objetivo para saludos, despedidas o frases muy cortas. "
            "Responde siempre en JSON con 'reply' y opcional 'frase_objetivo'."
        )

        self.context.append({"role": "user", "content": user_input})

        response = openai.chat.completions.create(
            model=self.model,
            messages=[{"role": "system", "content": system_prompt}] + self.context,
            temperature=0.7
        )

        raw_reply = response.choices[0].message.content.strip()

        # Intentamos parsear JSON
        import json
        try:
            data = json.loads(raw_reply)
            reply = data.get("reply", "").strip()
            frase_objetivo = data.get("frase_objetivo", "").strip() or None
        except Exception:
            # fallback si el modelo no devuelve JSON vÃ¡lido
            reply = raw_reply
            frase_objetivo = reply.split(".")[0]  # tomar primera frase como target

        # Chequeo de longitud
        word_count = len(reply.split())
        es_larga = word_count > 50

        self.context.append({"role": "assistant", "content": reply})

        print(f"ğŸ¤– Asistente: {reply} (palabras: {word_count})")
        print(f"ğŸ¯ Frase objetivo: {frase_objetivo}")

        return reply, frase_objetivo, es_larga


    def get_target_phrases(self, user_input, num_phrases=3):
        """
        Extrae frases cortas del contexto para practicar pronunciaciÃ³n.
        """
        prompt = f"""
        Extrae {num_phrases} frases clave en {self.language} del siguiente texto para que el usuario las practique:
        Texto: "{user_input}"
        Responde solo con una lista, sin explicaciÃ³n.
        """

        response = openai.ChatCompletion.create(
            model=self.model,
            messages=[{"role": "system", "content": "You are a language tutor."},
                      {"role": "user", "content": prompt}]
        )

        phrases = response["choices"][0]["message"]["content"].strip().split("\n")
        phrases = [p.strip("-â€¢ ") for p in phrases if p.strip()]

        return phrases[:num_phrases]
